{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "This notebook is a part of the implementation of the Neural Radiance Fields architecture as a project under the course EE5179: Deep Learning for Imaging.\n",
        "\n",
        "Extracting the poses and scene from the point cloud of the scene is the precursor to model training. In this notebook, we work on the output from the COLMAP software. From the `images.bin`, `points3d.bin` and `cameras.bin` files, the poses and scenes are extracted. This is equivalent to finding the direction and source of the ray being emitted from the camera towards the scene."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import collections\n",
        "import numpy as np\n",
        "import struct\n",
        "import json\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, the outputs from the COLMAP software are taken and read, and stored as variables to be worked upon later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8HO5ALJL3zw"
      },
      "outputs": [],
      "source": [
        "basedir = %pwd\n",
        "\n",
        "PATH= %pwd\n",
        "PATH2 = \"/colmap/outputs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## COLMAP Data Extraction\n",
        "A bunch of functions for extracting COLMAP data into variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdnKHhBZL3z1",
        "outputId": "0bdf582f-ad45-44fc-f80f-6e9fb03f08eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_cameras: 300\n",
            "num_images: 300\n",
            "num_points3D: 4259\n"
          ]
        }
      ],
      "source": [
        "CameraModel = collections.namedtuple(\n",
        "    \"CameraModel\", [\"model_id\", \"model_name\", \"num_params\"])\n",
        "Camera = collections.namedtuple(\n",
        "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"])\n",
        "BaseImage = collections.namedtuple(\n",
        "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
        "Point3D = collections.namedtuple(\n",
        "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"])\n",
        "\n",
        "class Image(BaseImage):\n",
        "    def qvec2rotmat(self):\n",
        "        return qvec2rotmat(self.qvec)\n",
        "\n",
        "\n",
        "CAMERA_MODELS = {\n",
        "    CameraModel(model_id=0, model_name=\"SIMPLE_PINHOLE\", num_params=3),\n",
        "    CameraModel(model_id=1, model_name=\"PINHOLE\", num_params=4),\n",
        "    CameraModel(model_id=2, model_name=\"SIMPLE_RADIAL\", num_params=4),\n",
        "    CameraModel(model_id=3, model_name=\"RADIAL\", num_params=5),\n",
        "    CameraModel(model_id=4, model_name=\"OPENCV\", num_params=8),\n",
        "    CameraModel(model_id=5, model_name=\"OPENCV_FISHEYE\", num_params=8),\n",
        "    CameraModel(model_id=6, model_name=\"FULL_OPENCV\", num_params=12),\n",
        "    CameraModel(model_id=7, model_name=\"FOV\", num_params=5),\n",
        "    CameraModel(model_id=8, model_name=\"SIMPLE_RADIAL_FISHEYE\", num_params=4),\n",
        "    CameraModel(model_id=9, model_name=\"RADIAL_FISHEYE\", num_params=5),\n",
        "    CameraModel(model_id=10, model_name=\"THIN_PRISM_FISHEYE\", num_params=12)\n",
        "}\n",
        "CAMERA_MODEL_IDS = dict([(camera_model.model_id, camera_model) \\\n",
        "                         for camera_model in CAMERA_MODELS])\n",
        "\n",
        "\n",
        "def read_next_bytes(fid, num_bytes, format_char_sequence, endian_character=\"<\"):\n",
        "    \"\"\"Read and unpack the next bytes from a binary file.\n",
        "    :param fid:\n",
        "    :param num_bytes: Sum of combination of {2, 4, 8}, e.g. 2, 6, 16, 30, etc.\n",
        "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
        "    :param endian_character: Any of {@, =, <, >, !}\n",
        "    :return: Tuple of read and unpacked values.\n",
        "    \"\"\"\n",
        "    data = fid.read(num_bytes)\n",
        "    return struct.unpack(endian_character + format_char_sequence, data)\n",
        "\n",
        "\n",
        "def read_cameras_text(path):\n",
        "    \"\"\"\n",
        "    see: src/base/reconstruction.cc\n",
        "        void Reconstruction::WriteCamerasText(const std::string& path)\n",
        "        void Reconstruction::ReadCamerasText(const std::string& path)\n",
        "    \"\"\"\n",
        "    cameras = {}\n",
        "    with open(path, \"r\") as fid:\n",
        "        while True:\n",
        "            line = fid.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line[0] != \"#\":\n",
        "                elems = line.split()\n",
        "                camera_id = int(elems[0])\n",
        "                model = elems[1]\n",
        "                width = int(elems[2])\n",
        "                height = int(elems[3])\n",
        "                params = np.array(tuple(map(float, elems[4:])))\n",
        "                cameras[camera_id] = Camera(id=camera_id, model=model,\n",
        "                                            width=width, height=height,\n",
        "                                            params=params)\n",
        "    return cameras\n",
        "\n",
        "\n",
        "def read_cameras_binary(path_to_model_file):\n",
        "    \"\"\"\n",
        "    see: src/base/reconstruction.cc\n",
        "        void Reconstruction::WriteCamerasBinary(const std::string& path)\n",
        "        void Reconstruction::ReadCamerasBinary(const std::string& path)\n",
        "    \"\"\"\n",
        "    cameras = {}\n",
        "    with open(path_to_model_file, \"rb\") as fid:\n",
        "        num_cameras = read_next_bytes(fid, 8, \"Q\")[0]\n",
        "        for camera_line_index in range(num_cameras):\n",
        "            camera_properties = read_next_bytes(\n",
        "                fid, num_bytes=24, format_char_sequence=\"iiQQ\")\n",
        "            camera_id = camera_properties[0]\n",
        "            model_id = camera_properties[1]\n",
        "            model_name = CAMERA_MODEL_IDS[camera_properties[1]].model_name\n",
        "            width = camera_properties[2]\n",
        "            height = camera_properties[3]\n",
        "            num_params = CAMERA_MODEL_IDS[model_id].num_params\n",
        "            params = read_next_bytes(fid, num_bytes=8*num_params,\n",
        "                                     format_char_sequence=\"d\"*num_params)\n",
        "            cameras[camera_id] = Camera(id=camera_id,\n",
        "                                        model=model_name,\n",
        "                                        width=width,\n",
        "                                        height=height,\n",
        "                                        params=np.array(params))\n",
        "        assert len(cameras) == num_cameras\n",
        "    # print(cameras.shape)\n",
        "    return cameras\n",
        "\n",
        "\n",
        "def read_images_text(path):\n",
        "    \"\"\"\n",
        "    see: src/base/reconstruction.cc\n",
        "        void Reconstruction::ReadImagesText(const std::string& path)\n",
        "        void Reconstruction::WriteImagesText(const std::string& path)\n",
        "    \"\"\"\n",
        "    images = {}\n",
        "    with open(path, \"r\") as fid:\n",
        "        while True:\n",
        "            line = fid.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line[0] != \"#\":\n",
        "                elems = line.split()\n",
        "                image_id = int(elems[0])\n",
        "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
        "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
        "                camera_id = int(elems[8])\n",
        "                image_name = elems[9]\n",
        "                elems = fid.readline().split()\n",
        "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
        "                                       tuple(map(float, elems[1::3]))])\n",
        "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
        "                images[image_id] = Image(\n",
        "                    id=image_id, qvec=qvec, tvec=tvec,\n",
        "                    camera_id=camera_id, name=image_name,\n",
        "                    xys=xys, point3D_ids=point3D_ids)\n",
        "    return images\n",
        "\n",
        "\n",
        "def read_images_binary(path_to_model_file):\n",
        "    \"\"\"\n",
        "    see: src/base/reconstruction.cc\n",
        "        void Reconstruction::ReadImagesBinary(const std::string& path)\n",
        "        void Reconstruction::WriteImagesBinary(const std::string& path)\n",
        "    \"\"\"\n",
        "    images = {}\n",
        "    with open(path_to_model_file, \"rb\") as fid:\n",
        "        num_reg_images = read_next_bytes(fid, 8, \"Q\")[0]\n",
        "        for image_index in range(num_reg_images):\n",
        "            binary_image_properties = read_next_bytes(\n",
        "                fid, num_bytes=64, format_char_sequence=\"idddddddi\")\n",
        "            image_id = binary_image_properties[0]\n",
        "            qvec = np.array(binary_image_properties[1:5])\n",
        "            tvec = np.array(binary_image_properties[5:8])\n",
        "            camera_id = binary_image_properties[8]\n",
        "            image_name = \"\"\n",
        "            current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
        "            while current_char != b\"\\x00\":   # look for the ASCII 0 entry\n",
        "                image_name += current_char.decode(\"utf-8\")\n",
        "                current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
        "            num_points2D = read_next_bytes(fid, num_bytes=8,\n",
        "                                           format_char_sequence=\"Q\")[0]\n",
        "            x_y_id_s = read_next_bytes(fid, num_bytes=24*num_points2D,\n",
        "                                       format_char_sequence=\"ddq\"*num_points2D)\n",
        "            xys = np.column_stack([tuple(map(float, x_y_id_s[0::3])),\n",
        "                                   tuple(map(float, x_y_id_s[1::3]))])\n",
        "            point3D_ids = np.array(tuple(map(int, x_y_id_s[2::3])))\n",
        "            images[image_id] = Image(\n",
        "                id=image_id, qvec=qvec, tvec=tvec,\n",
        "                camera_id=camera_id, name=image_name,\n",
        "                xys=xys, point3D_ids=point3D_ids)\n",
        "    return images\n",
        "\n",
        "\n",
        "def read_points3D_text(path):\n",
        "    \"\"\"\n",
        "    see: src/base/reconstruction.cc\n",
        "        void Reconstruction::ReadPoints3DText(const std::string& path)\n",
        "        void Reconstruction::WritePoints3DText(const std::string& path)\n",
        "    \"\"\"\n",
        "    points3D = {}\n",
        "    with open(path, \"r\") as fid:\n",
        "        while True:\n",
        "            line = fid.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line[0] != \"#\":\n",
        "                elems = line.split()\n",
        "                point3D_id = int(elems[0])\n",
        "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
        "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
        "                error = float(elems[7])\n",
        "                image_ids = np.array(tuple(map(int, elems[8::2])))\n",
        "                point2D_idxs = np.array(tuple(map(int, elems[9::2])))\n",
        "                points3D[point3D_id] = Point3D(id=point3D_id, xyz=xyz, rgb=rgb,\n",
        "                                               error=error, image_ids=image_ids,\n",
        "                                               point2D_idxs=point2D_idxs)\n",
        "    return points3D\n",
        "\n",
        "\n",
        "def read_points3d_binary(path_to_model_file):\n",
        "    \"\"\"\n",
        "    see: src/base/reconstruction.cc\n",
        "        void Reconstruction::ReadPoints3DBinary(const std::string& path)\n",
        "        void Reconstruction::WritePoints3DBinary(const std::string& path)\n",
        "    \"\"\"\n",
        "    points3D = {}\n",
        "    with open(path_to_model_file, \"rb\") as fid:\n",
        "        num_points = read_next_bytes(fid, 8, \"Q\")[0]\n",
        "        for point_line_index in range(num_points):\n",
        "            binary_point_line_properties = read_next_bytes(\n",
        "                fid, num_bytes=43, format_char_sequence=\"QdddBBBd\")\n",
        "            point3D_id = binary_point_line_properties[0]\n",
        "            xyz = np.array(binary_point_line_properties[1:4])\n",
        "            rgb = np.array(binary_point_line_properties[4:7])\n",
        "            error = np.array(binary_point_line_properties[7])\n",
        "            track_length = read_next_bytes(\n",
        "                fid, num_bytes=8, format_char_sequence=\"Q\")[0]\n",
        "            track_elems = read_next_bytes(\n",
        "                fid, num_bytes=8*track_length,\n",
        "                format_char_sequence=\"ii\"*track_length)\n",
        "            image_ids = np.array(tuple(map(int, track_elems[0::2])))\n",
        "            point2D_idxs = np.array(tuple(map(int, track_elems[1::2])))\n",
        "            points3D[point3D_id] = Point3D(\n",
        "                id=point3D_id, xyz=xyz, rgb=rgb,\n",
        "                error=error, image_ids=image_ids,\n",
        "                point2D_idxs=point2D_idxs)\n",
        "    return points3D\n",
        "\n",
        "\n",
        "def read_model(path, ext):\n",
        "    if ext == \".txt\":\n",
        "        cameras = read_cameras_text(os.path.join(path, \"cameras\" + ext))\n",
        "        images = read_images_text(os.path.join(path, \"images\" + ext))\n",
        "        points3D = read_points3D_text(os.path.join(path, \"points3D\") + ext)\n",
        "    else:\n",
        "        cameras = read_cameras_binary(os.path.join(path, \"cameras\" + ext))\n",
        "        images = read_images_binary(os.path.join(path, \"images\" + ext))\n",
        "        points3D = read_points3d_binary(os.path.join(path, \"points3D\") + ext)\n",
        "    return cameras, images, points3D\n",
        "\n",
        "\n",
        "def qvec2rotmat(qvec):\n",
        "    return np.array([\n",
        "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
        "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
        "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
        "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
        "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
        "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
        "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
        "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
        "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
        "\n",
        "\n",
        "def rotmat2qvec(R):\n",
        "    Rxx, Ryx, Rzx, Rxy, Ryy, Rzy, Rxz, Ryz, Rzz = R.flat\n",
        "    K = np.array([\n",
        "        [Rxx - Ryy - Rzz, 0, 0, 0],\n",
        "        [Ryx + Rxy, Ryy - Rxx - Rzz, 0, 0],\n",
        "        [Rzx + Rxz, Rzy + Ryz, Rzz - Rxx - Ryy, 0],\n",
        "        [Ryz - Rzy, Rzx - Rxz, Rxy - Ryx, Rxx + Ryy + Rzz]]) / 3.0\n",
        "    eigvals, eigvecs = np.linalg.eigh(K)\n",
        "    qvec = eigvecs[[3, 0, 1, 2], np.argmax(eigvals)]\n",
        "    if qvec[0] < 0:\n",
        "        qvec *= -1\n",
        "    return qvec\n",
        "\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) != 3:\n",
        "        print(\"Usage: python read_model.py path/to/model/folder [.txt,.bin]\")\n",
        "        return\n",
        "\n",
        "    cameras, images, points3D = read_model(path=PATH+PATH2, ext=\".bin\")\n",
        "\n",
        "    print(\"num_cameras:\", len(cameras))\n",
        "    print(\"num_images:\", len(images))\n",
        "    print(\"num_points3D:\", len(points3D))\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7idMd8uL3z6"
      },
      "outputs": [],
      "source": [
        "def get_bbox_corners(points):\n",
        "  lower = points.min(axis=0)\n",
        "  upper = points.max(axis=0)\n",
        "  return np.stack([lower, upper])\n",
        "\n",
        "def filter_outlier_points(points, inner_percentile):\n",
        "  \"\"\"Filters outlier points.\"\"\"\n",
        "  outer = 1.0 - inner_percentile\n",
        "  lower = outer / 2.0\n",
        "  upper = 1.0 - lower\n",
        "  centers_min = np.quantile(points, lower, axis=0)\n",
        "  centers_max = np.quantile(points, upper, axis=0)\n",
        "  result = points.copy()\n",
        "\n",
        "  too_near = np.any(result < centers_min[None, :], axis=1)\n",
        "  too_far = np.any(result > centers_max[None, :], axis=1)\n",
        "\n",
        "  return result[~(too_near | too_far)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir7e1hzML3z7",
        "outputId": "6113d546-b7d9-45e0-babe-a75d45f3a1e5"
      },
      "outputs": [],
      "source": [
        "camdata = read_cameras_binary(PATH+PATH2+\"/cameras.bin\")\n",
        "camdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbwJ057fL3z9",
        "outputId": "df007a6d-2789-43bd-937f-957847462f91"
      },
      "outputs": [],
      "source": [
        "focal = np.array([item.params[0] for item in camdata.values()])\n",
        "focal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function converts all the COLMAP data into a readable numpy file, using the above defined functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6i5F_wML3z-",
        "outputId": "9e628b04-433b-47b7-8844-3a40d4273dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cameras Camera(id=1, model='SIMPLE_RADIAL', width=400, height=400, params=array([ 6.11335793e+02,  2.00000000e+02,  2.00000000e+02, -2.40112893e-02]))\n",
            "*********\n",
            "Images # 300\n",
            "frame_0000.jpg\n",
            "frame_0003.jpg\n",
            "frame_0007.jpg\n",
            "frame_0010.jpg\n",
            "frame_0014.jpg\n",
            "frame_0017.jpg\n",
            "frame_0021.jpg\n",
            "frame_0024.jpg\n",
            "frame_0028.jpg\n",
            "frame_0031.jpg\n",
            "frame_0035.jpg\n",
            "frame_0038.jpg\n",
            "frame_0042.jpg\n",
            "frame_0045.jpg\n",
            "frame_0049.jpg\n",
            "frame_0052.jpg\n",
            "frame_0056.jpg\n",
            "frame_0059.jpg\n",
            "frame_0063.jpg\n",
            "frame_0066.jpg\n",
            "frame_0070.jpg\n",
            "frame_0073.jpg\n",
            "frame_0077.jpg\n",
            "frame_0080.jpg\n",
            "frame_0084.jpg\n",
            "frame_0087.jpg\n",
            "frame_0090.jpg\n",
            "frame_0094.jpg\n",
            "frame_0097.jpg\n",
            "frame_0101.jpg\n",
            "frame_0104.jpg\n",
            "frame_0108.jpg\n",
            "frame_0111.jpg\n",
            "frame_0115.jpg\n",
            "frame_0118.jpg\n",
            "frame_0122.jpg\n",
            "frame_0125.jpg\n",
            "frame_0129.jpg\n",
            "frame_0132.jpg\n",
            "frame_0136.jpg\n",
            "frame_0139.jpg\n",
            "frame_0143.jpg\n",
            "frame_0146.jpg\n",
            "frame_0150.jpg\n",
            "frame_0153.jpg\n",
            "frame_0157.jpg\n",
            "frame_0160.jpg\n",
            "frame_0164.jpg\n",
            "frame_0167.jpg\n",
            "frame_0171.jpg\n",
            "frame_0174.jpg\n",
            "frame_0177.jpg\n",
            "frame_0181.jpg\n",
            "frame_0184.jpg\n",
            "frame_0188.jpg\n",
            "frame_0191.jpg\n",
            "frame_0195.jpg\n",
            "frame_0198.jpg\n",
            "frame_0202.jpg\n",
            "frame_0205.jpg\n",
            "frame_0209.jpg\n",
            "frame_0212.jpg\n",
            "frame_0216.jpg\n",
            "frame_0219.jpg\n",
            "frame_0223.jpg\n",
            "frame_0226.jpg\n",
            "frame_0230.jpg\n",
            "frame_0233.jpg\n",
            "frame_0237.jpg\n",
            "frame_0240.jpg\n",
            "frame_0244.jpg\n",
            "frame_0247.jpg\n",
            "frame_0251.jpg\n",
            "frame_0254.jpg\n",
            "frame_0258.jpg\n",
            "frame_0261.jpg\n",
            "frame_0264.jpg\n",
            "frame_0268.jpg\n",
            "frame_0271.jpg\n",
            "frame_0275.jpg\n",
            "frame_0278.jpg\n",
            "frame_0282.jpg\n",
            "frame_0285.jpg\n",
            "frame_0289.jpg\n",
            "frame_0292.jpg\n",
            "frame_0296.jpg\n",
            "frame_0299.jpg\n",
            "frame_0303.jpg\n",
            "frame_0306.jpg\n",
            "frame_0310.jpg\n",
            "frame_0313.jpg\n",
            "frame_0317.jpg\n",
            "frame_0320.jpg\n",
            "frame_0324.jpg\n",
            "frame_0327.jpg\n",
            "frame_0331.jpg\n",
            "frame_0334.jpg\n",
            "frame_0338.jpg\n",
            "frame_0341.jpg\n",
            "frame_0345.jpg\n",
            "frame_0348.jpg\n",
            "frame_0351.jpg\n",
            "frame_0355.jpg\n",
            "frame_0358.jpg\n",
            "frame_0362.jpg\n",
            "frame_0365.jpg\n",
            "frame_0369.jpg\n",
            "frame_0372.jpg\n",
            "frame_0376.jpg\n",
            "frame_0379.jpg\n",
            "frame_0383.jpg\n",
            "frame_0386.jpg\n",
            "frame_0390.jpg\n",
            "frame_0393.jpg\n",
            "frame_0397.jpg\n",
            "frame_0400.jpg\n",
            "frame_0404.jpg\n",
            "frame_0407.jpg\n",
            "frame_0411.jpg\n",
            "frame_0414.jpg\n",
            "frame_0418.jpg\n",
            "frame_0421.jpg\n",
            "frame_0425.jpg\n",
            "frame_0428.jpg\n",
            "frame_0432.jpg\n",
            "frame_0435.jpg\n",
            "frame_0438.jpg\n",
            "frame_0442.jpg\n",
            "frame_0445.jpg\n",
            "frame_0449.jpg\n",
            "frame_0452.jpg\n",
            "frame_0456.jpg\n",
            "frame_0459.jpg\n",
            "frame_0463.jpg\n",
            "frame_0466.jpg\n",
            "frame_0470.jpg\n",
            "frame_0473.jpg\n",
            "frame_0477.jpg\n",
            "frame_0480.jpg\n",
            "frame_0484.jpg\n",
            "frame_0487.jpg\n",
            "frame_0491.jpg\n",
            "frame_0494.jpg\n",
            "frame_0498.jpg\n",
            "frame_0501.jpg\n",
            "frame_0505.jpg\n",
            "frame_0508.jpg\n",
            "frame_0512.jpg\n",
            "frame_0515.jpg\n",
            "frame_0519.jpg\n",
            "frame_0522.jpg\n",
            "frame_0525.jpg\n",
            "frame_0529.jpg\n",
            "frame_0532.jpg\n",
            "frame_0536.jpg\n",
            "frame_0539.jpg\n",
            "frame_0543.jpg\n",
            "frame_0546.jpg\n",
            "frame_0550.jpg\n",
            "frame_0553.jpg\n",
            "frame_0557.jpg\n",
            "frame_0560.jpg\n",
            "frame_0564.jpg\n",
            "frame_0567.jpg\n",
            "frame_0571.jpg\n",
            "frame_0574.jpg\n",
            "frame_0578.jpg\n",
            "frame_0581.jpg\n",
            "frame_0585.jpg\n",
            "frame_0588.jpg\n",
            "frame_0592.jpg\n",
            "frame_0595.jpg\n",
            "frame_0599.jpg\n",
            "frame_0602.jpg\n",
            "frame_0606.jpg\n",
            "frame_0609.jpg\n",
            "frame_0612.jpg\n",
            "frame_0616.jpg\n",
            "frame_0619.jpg\n",
            "frame_0623.jpg\n",
            "frame_0626.jpg\n",
            "frame_0630.jpg\n",
            "frame_0633.jpg\n",
            "frame_0637.jpg\n",
            "frame_0640.jpg\n",
            "frame_0644.jpg\n",
            "frame_0647.jpg\n",
            "frame_0651.jpg\n",
            "frame_0654.jpg\n",
            "frame_0658.jpg\n",
            "frame_0661.jpg\n",
            "frame_0665.jpg\n",
            "frame_0668.jpg\n",
            "frame_0672.jpg\n",
            "frame_0675.jpg\n",
            "frame_0679.jpg\n",
            "frame_0682.jpg\n",
            "frame_0686.jpg\n",
            "frame_0689.jpg\n",
            "frame_0693.jpg\n",
            "frame_0696.jpg\n",
            "frame_0699.jpg\n",
            "frame_0703.jpg\n",
            "frame_0706.jpg\n",
            "frame_0710.jpg\n",
            "frame_0713.jpg\n",
            "frame_0717.jpg\n",
            "frame_0720.jpg\n",
            "frame_0724.jpg\n",
            "frame_0727.jpg\n",
            "frame_0731.jpg\n",
            "frame_0734.jpg\n",
            "frame_0738.jpg\n",
            "frame_0741.jpg\n",
            "frame_0745.jpg\n",
            "frame_0748.jpg\n",
            "frame_0752.jpg\n",
            "frame_0755.jpg\n",
            "frame_0759.jpg\n",
            "frame_0762.jpg\n",
            "frame_0766.jpg\n",
            "frame_0769.jpg\n",
            "frame_0773.jpg\n",
            "frame_0776.jpg\n",
            "frame_0780.jpg\n",
            "frame_0783.jpg\n",
            "frame_0786.jpg\n",
            "frame_0790.jpg\n",
            "frame_0793.jpg\n",
            "frame_0797.jpg\n",
            "frame_0800.jpg\n",
            "frame_0804.jpg\n",
            "frame_0807.jpg\n",
            "frame_0811.jpg\n",
            "frame_0814.jpg\n",
            "frame_0818.jpg\n",
            "frame_0821.jpg\n",
            "frame_0825.jpg\n",
            "frame_0828.jpg\n",
            "frame_0832.jpg\n",
            "frame_0835.jpg\n",
            "frame_0839.jpg\n",
            "frame_0842.jpg\n",
            "frame_0846.jpg\n",
            "frame_0849.jpg\n",
            "frame_0853.jpg\n",
            "frame_0856.jpg\n",
            "frame_0860.jpg\n",
            "frame_0863.jpg\n",
            "frame_0867.jpg\n",
            "frame_0870.jpg\n",
            "frame_0873.jpg\n",
            "frame_0877.jpg\n",
            "frame_0880.jpg\n",
            "frame_0884.jpg\n",
            "frame_0887.jpg\n",
            "frame_0891.jpg\n",
            "frame_0894.jpg\n",
            "frame_0898.jpg\n",
            "frame_0901.jpg\n",
            "frame_0905.jpg\n",
            "frame_0908.jpg\n",
            "frame_0912.jpg\n",
            "frame_0915.jpg\n",
            "frame_0919.jpg\n",
            "frame_0922.jpg\n",
            "frame_0926.jpg\n",
            "frame_0929.jpg\n",
            "frame_0933.jpg\n",
            "frame_0936.jpg\n",
            "frame_0940.jpg\n",
            "frame_0943.jpg\n",
            "frame_0947.jpg\n",
            "frame_0950.jpg\n",
            "frame_0954.jpg\n",
            "frame_0957.jpg\n",
            "frame_0960.jpg\n",
            "frame_0964.jpg\n",
            "frame_0967.jpg\n",
            "frame_0971.jpg\n",
            "frame_0974.jpg\n",
            "frame_0978.jpg\n",
            "frame_0981.jpg\n",
            "frame_0985.jpg\n",
            "frame_0988.jpg\n",
            "frame_0992.jpg\n",
            "frame_0995.jpg\n",
            "frame_0999.jpg\n",
            "frame_1002.jpg\n",
            "frame_1006.jpg\n",
            "frame_1009.jpg\n",
            "frame_1013.jpg\n",
            "frame_1016.jpg\n",
            "frame_1020.jpg\n",
            "frame_1023.jpg\n",
            "frame_1027.jpg\n",
            "frame_1030.jpg\n",
            "frame_1034.jpg\n",
            "frame_1037.jpg\n",
            "frame_1041.jpg\n",
            "bbox_corners  [[-4.79405338 -1.73098776 -0.8483751 ]\n",
            " [ 6.10460326  2.01013005  8.95796339]]\n",
            "scene_center  [0.65527494 0.13957115 4.05479415] 0.06609038110091398\n",
            "(300, 17)\n",
            "Done with imgs2poses\n"
          ]
        }
      ],
      "source": [
        "def load_colmap_data(realdir):\n",
        "    camerasfile = os.path.join(realdir, PATH2+\"/cameras.bin\")\n",
        "    camdata = read_cameras_binary(PATH+PATH2+\"/cameras.bin\")\n",
        "\n",
        "    list_of_keys = list(camdata.keys())\n",
        "    cam = camdata[list_of_keys[0]]\n",
        "    print( 'Cameras', cam)\n",
        "    # print(\"Cameras[0] \", camdata[0])\n",
        "\n",
        "    h, w, f = cam.height, cam.width, cam.params[0]\n",
        "    # w, h, f = factor * w, factor * h, factor * f\n",
        "    hwf = np.array([h, w, f]).reshape([3,1])\n",
        "\n",
        "    print(\"*********\")\n",
        "\n",
        "    imagesfile = os.path.join(realdir, PATH2+'/images.bin')\n",
        "    imdata = read_images_binary(PATH+PATH2+'/images.bin')\n",
        "\n",
        "    w2c_mats = []\n",
        "    bottom = np.array([0,0,0,1.]).reshape([1,4])\n",
        "\n",
        "    names = [imdata[k].name for k in imdata]\n",
        "    img_keys = [k for k in imdata]\n",
        "\n",
        "    print( 'Images #', len(names))\n",
        "    perm = np.argsort(names)\n",
        "\n",
        "    points3dfile = os.path.join(realdir, PATH2+'/points3D.bin')\n",
        "    pts3d = read_points3d_binary(PATH+PATH2+'/points3D.bin')\n",
        "\n",
        "    # extract point 3D xyz\n",
        "    point_cloud = []\n",
        "    for key in pts3d:\n",
        "        point_cloud.append(pts3d[key].xyz)\n",
        "\n",
        "    point_cloud = np.stack(point_cloud, 0)\n",
        "    point_cloud = filter_outlier_points(point_cloud, 0.95)\n",
        "\n",
        "    bounds_mats = []\n",
        "\n",
        "    upper_bound = 1000\n",
        "\n",
        "    if upper_bound < len(img_keys):\n",
        "        print(\"Only keeping \" + str(upper_bound) + \" images!\")\n",
        "\n",
        "    for i in perm[0:min(upper_bound, len(img_keys))]:\n",
        "        im = imdata[img_keys[i]]\n",
        "        print(im.name)\n",
        "        R = im.qvec2rotmat()\n",
        "        t = im.tvec.reshape([3,1])\n",
        "        m = np.concatenate([np.concatenate([R, t], 1), bottom], 0)\n",
        "        w2c_mats.append(m)\n",
        "\n",
        "        pts_3d_idx = im.point3D_ids\n",
        "        pts_3d_vis_idx = pts_3d_idx[pts_3d_idx >= 0]\n",
        "\n",
        "        #\n",
        "        depth_list = []\n",
        "        for k in range(len(pts_3d_vis_idx)):\n",
        "          point_info = pts3d[pts_3d_vis_idx[k]]\n",
        "          P_g = point_info.xyz\n",
        "          P_c = np.dot(R, P_g.reshape(3, 1)) + t.reshape(3, 1)\n",
        "          depth_list.append(P_c[2])\n",
        "\n",
        "        zs = np.array(depth_list)\n",
        "        close_depth, inf_depth = np.percentile(zs, 5), np.percentile(zs, 95)\n",
        "        bounds = np.array([close_depth, inf_depth])\n",
        "        bounds_mats.append(bounds)\n",
        "\n",
        "    w2c_mats = np.stack(w2c_mats, 0)\n",
        "    # bounds_mats = np.stack(bounds_mats, 0)\n",
        "    c2w_mats = np.linalg.inv(w2c_mats)\n",
        "\n",
        "    # bbox_corners = get_bbox_corners(point_cloud)\n",
        "    # also add camera\n",
        "    bbox_corners = get_bbox_corners(\n",
        "                    np.concatenate([point_cloud, c2w_mats[:, :3, 3]], axis=0))\n",
        "\n",
        "    scene_center = np.mean(bbox_corners, axis=0)\n",
        "    scene_scale = 1.0 / np.sqrt(np.sum((bbox_corners[1] - bbox_corners[0]) ** 2))\n",
        "\n",
        "    print('bbox_corners ', bbox_corners)\n",
        "    print('scene_center ', scene_center, scene_scale)\n",
        "\n",
        "    poses = c2w_mats[:, :3, :4].transpose([1,2,0])\n",
        "    poses = np.concatenate([poses, np.tile(hwf[..., np.newaxis],\n",
        "                                        [1,1,poses.shape[-1]])], 1)\n",
        "\n",
        "    # must switch to [-y, x, z] from [x, -y, -z], NOT [r, u, -t]\n",
        "    poses = np.concatenate([poses[:, 1:2, :], poses[:, 0:1, :],\n",
        "                            -poses[:, 2:3, :],\n",
        "                            poses[:, 3:4, :],\n",
        "                            poses[:, 4:5, :]], 1)\n",
        "\n",
        "    save_arr = []\n",
        "\n",
        "    for i in range((poses.shape[2])):\n",
        "        save_arr.append(np.concatenate([poses[..., i].ravel(), bounds_mats[i]], 0))\n",
        "\n",
        "    save_arr = np.array(save_arr)\n",
        "    print(save_arr.shape)\n",
        "    np.save(os.path.join(realdir, 'poses_bounds.npy'), save_arr)\n",
        "    with open(os.path.join(realdir, 'scene.json'), 'w') as f:\n",
        "      json.dump({\n",
        "          'scale': scene_scale,\n",
        "          'center': scene_center.tolist(),\n",
        "          'bbox': bbox_corners.tolist(),\n",
        "      }, f, indent=2)\n",
        "\n",
        "basedir = PATH\n",
        "load_colmap_data(basedir)\n",
        "print( 'Done with imgs2poses' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHhuXsjdL3z_"
      },
      "source": [
        "## COLMAP to Poses\n",
        "\n",
        "Here, poses are extracted from the COLMAP data stored earlier. This also involves world to camera transitions in order to obtain image specific information, and normalizations, and other operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xThyfQvL30C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, imageio\n",
        "\n",
        "\n",
        "########## Slightly modified version of LLFF data loading code\n",
        "##########  see https://github.com/Fyusion/LLFF for original\n",
        "\n",
        "def _minify(basedir, factors=[], resolutions=[]):\n",
        "    needtoload = False\n",
        "    for r in factors:\n",
        "        imgdir = os.path.join(basedir, 'images_{}'.format(r))\n",
        "        if not os.path.exists(imgdir):\n",
        "            needtoload = True\n",
        "    for r in resolutions:\n",
        "        imgdir = os.path.join(basedir, 'images_{}x{}'.format(r[1], r[0]))\n",
        "        if not os.path.exists(imgdir):\n",
        "            needtoload = True\n",
        "    if not needtoload:\n",
        "        return\n",
        "\n",
        "    from shutil import copy\n",
        "    from subprocess import check_output\n",
        "\n",
        "    imgdir = os.path.join(basedir, 'images')\n",
        "    imgs = [os.path.join(imgdir, f) for f in sorted(os.listdir(imgdir))]\n",
        "    imgs = [f for f in imgs if any([f.endswith(ex) for ex in ['JPG', 'jpg', 'png', 'jpeg', 'PNG']])]\n",
        "    imgdir_orig = imgdir\n",
        "\n",
        "    wd = os.getcwd()\n",
        "\n",
        "    for r in factors + resolutions:\n",
        "        if isinstance(r, int):\n",
        "            name = 'images_{}'.format(r)\n",
        "            resizearg = '{}%'.format(100./r)\n",
        "        else:\n",
        "            name = 'images_{}x{}'.format(r[1], r[0])\n",
        "            resizearg = '{}x{}'.format(r[1], r[0])\n",
        "        imgdir = os.path.join(basedir, name)\n",
        "        if os.path.exists(imgdir):\n",
        "            continue\n",
        "\n",
        "        print('Minifying', r, basedir)\n",
        "\n",
        "        os.makedirs(imgdir)\n",
        "        check_output('cp {}/* {}'.format(imgdir_orig, imgdir), shell=True)\n",
        "\n",
        "        ext = imgs[0].split('.')[-1]\n",
        "        args = ' '.join(['mogrify', '-resize', resizearg, '-format', 'png', '*.{}'.format(ext)])\n",
        "        print(args)\n",
        "        os.chdir(imgdir)\n",
        "        check_output(args, shell=True)\n",
        "        os.chdir(wd)\n",
        "\n",
        "        if ext != 'png':\n",
        "            check_output('rm {}/*.{}'.format(imgdir, ext), shell=True)\n",
        "            print('Removed duplicates')\n",
        "        print('Done')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _load_data(basedir, factor=None, width=None, height=None, load_imgs=True):\n",
        "\n",
        "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
        "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
        "    bds = poses_arr[:, -2:].transpose([1,0])\n",
        "\n",
        "    img0 = [os.path.join(basedir, 'images', f) for f in sorted(os.listdir(os.path.join(basedir, 'images'))) \\\n",
        "            if f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')][0]\n",
        "    sh = imageio.imread(img0).shape\n",
        "\n",
        "    sfx = ''\n",
        "\n",
        "    if factor is not None:\n",
        "        sfx = '_{}'.format(factor)\n",
        "        _minify(basedir, factors=[factor])\n",
        "        factor = factor\n",
        "    elif height is not None:\n",
        "        factor = sh[0] / float(height)\n",
        "        width = int(sh[1] / factor)\n",
        "        _minify(basedir, resolutions=[[height, width]])\n",
        "        sfx = '_{}x{}'.format(width, height)\n",
        "    elif width is not None:\n",
        "        factor = sh[1] / float(width)\n",
        "        height = int(sh[0] / factor)\n",
        "        _minify(basedir, resolutions=[[height, width]])\n",
        "        sfx = '_{}x{}'.format(width, height)\n",
        "    else:\n",
        "        factor = 1\n",
        "\n",
        "    imgdir = os.path.join(basedir, 'images' + sfx)\n",
        "    if not os.path.exists(imgdir):\n",
        "        print( imgdir, 'does not exist, returning' )\n",
        "        return\n",
        "\n",
        "    imgfiles = [os.path.join(imgdir, f) for f in sorted(os.listdir(imgdir)) if f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')]\n",
        "    if poses.shape[-1] != len(imgfiles):\n",
        "        print( 'Mismatch between imgs {} and poses {} !!!!'.format(len(imgfiles), poses.shape[-1]) )\n",
        "        return\n",
        "\n",
        "    sh = imageio.imread(imgfiles[0]).shape\n",
        "    poses[:2, 4, :] = np.array(sh[:2]).reshape([2, 1])\n",
        "    poses[2, 4, :] = poses[2, 4, :] * 1./factor\n",
        "\n",
        "    if not load_imgs:\n",
        "        return poses, bds\n",
        "\n",
        "    def imread(f):\n",
        "        if f.endswith('png'):\n",
        "            return imageio.imread(f, ignoregamma=True)\n",
        "        else:\n",
        "            return imageio.imread(f)\n",
        "\n",
        "    imgs = imgs = [imread(f)[...,:3]/255. for f in imgfiles]\n",
        "    imgs = np.stack(imgs, -1)\n",
        "\n",
        "    print('Loaded image data', imgs.shape, poses[:,-1,0])\n",
        "    return poses, bds, imgs\n",
        "\n",
        "def normalize(x):\n",
        "    return x / np.linalg.norm(x)\n",
        "\n",
        "def viewmatrix(z, up, pos):\n",
        "    vec2 = normalize(z)\n",
        "    vec1_avg = up\n",
        "    vec0 = normalize(np.cross(vec1_avg, vec2))\n",
        "    vec1 = normalize(np.cross(vec2, vec0))\n",
        "    m = np.stack([vec0, vec1, vec2, pos], 1)\n",
        "    return m\n",
        "\n",
        "def ptstocam(pts, c2w):\n",
        "    tt = np.matmul(c2w[:3,:3].T, (pts-c2w[:3,3])[...,np.newaxis])[...,0]\n",
        "    return tt\n",
        "\n",
        "def poses_avg(poses):\n",
        "\n",
        "    hwf = poses[0, :3, -1:]\n",
        "\n",
        "    center = poses[:, :3, 3].mean(0)\n",
        "    vec2 = normalize(poses[:, :3, 2].sum(0))\n",
        "    up = poses[:, :3, 1].sum(0)\n",
        "    c2w = np.concatenate([viewmatrix(vec2, up, center), hwf], 1)\n",
        "\n",
        "    return c2w\n",
        "\n",
        "def render_path_spiral(c2w, up, rads, focal, zdelta, zrate, rots, N):\n",
        "    render_poses = []\n",
        "    rads = np.array(list(rads) + [1.])\n",
        "    hwf = c2w[:,4:5]\n",
        "\n",
        "    for theta in np.linspace(0., 2. * np.pi * rots, N+1)[:-1]:\n",
        "        c = np.dot(c2w[:3,:4], np.array([np.cos(theta), -np.sin(theta), -np.sin(theta*zrate), 1.]) * rads)\n",
        "        z = normalize(c - np.dot(c2w[:3,:4], np.array([0,0,-focal, 1.])))\n",
        "        render_poses.append(np.concatenate([viewmatrix(z, up, c), hwf], 1))\n",
        "    return render_poses\n",
        "\n",
        "def recenter_poses(poses):\n",
        "\n",
        "    poses_ = poses+0\n",
        "    bottom = np.reshape([0,0,0,1.], [1,4])\n",
        "    c2w = poses_avg(poses)\n",
        "    c2w = np.concatenate([c2w[:3,:4], bottom], -2)\n",
        "    bottom = np.tile(np.reshape(bottom, [1,1,4]), [poses.shape[0],1,1])\n",
        "    poses = np.concatenate([poses[:,:3,:4], bottom], -2)\n",
        "\n",
        "    poses = np.linalg.inv(c2w) @ poses\n",
        "    poses_[:,:3,:4] = poses[:,:3,:4]\n",
        "    poses = poses_\n",
        "    return poses\n",
        "\n",
        "\n",
        "#####################\n",
        "\n",
        "\n",
        "def spherify_poses(poses, bds):\n",
        "\n",
        "    p34_to_44 = lambda p : np.concatenate([p, np.tile(np.reshape(np.eye(4)[-1,:], [1,1,4]), [p.shape[0], 1,1])], 1)\n",
        "\n",
        "    rays_d = poses[:,:3,2:3]\n",
        "    rays_o = poses[:,:3,3:4]\n",
        "\n",
        "    def min_line_dist(rays_o, rays_d):\n",
        "        A_i = np.eye(3) - rays_d * np.transpose(rays_d, [0,2,1])\n",
        "        b_i = -A_i @ rays_o\n",
        "        pt_mindist = np.squeeze(-np.linalg.inv((np.transpose(A_i, [0,2,1]) @ A_i).mean(0)) @ (b_i).mean(0))\n",
        "        return pt_mindist\n",
        "\n",
        "    pt_mindist = min_line_dist(rays_o, rays_d)\n",
        "\n",
        "    center = pt_mindist\n",
        "    up = (poses[:,:3,3] - center).mean(0)\n",
        "\n",
        "    vec0 = normalize(up)\n",
        "    vec1 = normalize(np.cross([.1,.2,.3], vec0))\n",
        "    vec2 = normalize(np.cross(vec0, vec1))\n",
        "    pos = center\n",
        "    c2w = np.stack([vec1, vec2, vec0, pos], 1)\n",
        "\n",
        "    poses_reset = np.linalg.inv(p34_to_44(c2w[None])) @ p34_to_44(poses[:,:3,:4])\n",
        "\n",
        "    rad = np.sqrt(np.mean(np.sum(np.square(poses_reset[:,:3,3]), -1)))\n",
        "\n",
        "    sc = 1./rad\n",
        "    poses_reset[:,:3,3] *= sc\n",
        "    bds *= sc\n",
        "    rad *= sc\n",
        "\n",
        "    centroid = np.mean(poses_reset[:,:3,3], 0)\n",
        "    zh = centroid[2]\n",
        "    radcircle = np.sqrt(rad**2-zh**2)\n",
        "    new_poses = []\n",
        "\n",
        "    for th in np.linspace(0.,2.*np.pi, 120):\n",
        "\n",
        "        camorigin = np.array([radcircle * np.cos(th), radcircle * np.sin(th), zh])\n",
        "        up = np.array([0,0,-1.])\n",
        "\n",
        "        vec2 = normalize(camorigin)\n",
        "        vec0 = normalize(np.cross(vec2, up))\n",
        "        vec1 = normalize(np.cross(vec2, vec0))\n",
        "        pos = camorigin\n",
        "        p = np.stack([vec0, vec1, vec2, pos], 1)\n",
        "\n",
        "        new_poses.append(p)\n",
        "\n",
        "    new_poses = np.stack(new_poses, 0)\n",
        "\n",
        "    new_poses = np.concatenate([new_poses, np.broadcast_to(poses[0,:3,-1:], new_poses[:,:3,-1:].shape)], -1)\n",
        "    poses_reset = np.concatenate([poses_reset[:,:3,:4], np.broadcast_to(poses[0,:3,-1:], poses_reset[:,:3,-1:].shape)], -1)\n",
        "\n",
        "    return poses_reset, new_poses, bds\n",
        "\n",
        "\n",
        "def load_llff_data(basedir, factor=8, recenter=True, bd_factor=.75, spherify=False, path_zflat=False):\n",
        "\n",
        "\n",
        "    poses, bds, imgs = _load_data(basedir, factor=factor) # factor=8 downsamples original imgs by 8x\n",
        "    print('Loaded', basedir, bds.min(), bds.max())\n",
        "\n",
        "    # Correct rotation matrix ordering and move variable dim to axis 0\n",
        "    poses = np.concatenate([poses[:, 1:2, :], -poses[:, 0:1, :], poses[:, 2:, :]], 1)\n",
        "    poses = np.moveaxis(poses, -1, 0).astype(np.float32)\n",
        "    imgs = np.moveaxis(imgs, -1, 0).astype(np.float32)\n",
        "    images = imgs\n",
        "    bds = np.moveaxis(bds, -1, 0).astype(np.float32)\n",
        "\n",
        "    # Rescale if bd_factor is provided\n",
        "    sc = 1. if bd_factor is None else 1./(bds.min() * bd_factor)\n",
        "    poses[:,:3,3] *= sc\n",
        "    bds *= sc\n",
        "\n",
        "    if recenter:\n",
        "        poses = recenter_poses(poses)\n",
        "\n",
        "    if spherify:\n",
        "        poses, render_poses, bds = spherify_poses(poses, bds)\n",
        "\n",
        "    else:\n",
        "\n",
        "        c2w = poses_avg(poses)\n",
        "        print('recentered', c2w.shape)\n",
        "        print(c2w[:3,:4])\n",
        "\n",
        "        ## Get spiral\n",
        "        # Get average pose\n",
        "        up = normalize(poses[:, :3, 1].sum(0))\n",
        "\n",
        "        # Find a reasonable \"focus depth\" for this dataset\n",
        "        close_depth, inf_depth = bds.min()*.9, bds.max()*5.\n",
        "        dt = .75\n",
        "        mean_dz = 1./(((1.-dt)/close_depth + dt/inf_depth))\n",
        "        focal = mean_dz\n",
        "\n",
        "        # Get radii for spiral path\n",
        "        shrink_factor = .8\n",
        "        zdelta = close_depth * .2\n",
        "        tt = poses[:,:3,3] # ptstocam(poses[:3,3,:].T, c2w).T\n",
        "        rads = np.percentile(np.abs(tt), 90, 0)\n",
        "        c2w_path = c2w\n",
        "        N_views = 120\n",
        "        N_rots = 2\n",
        "        if path_zflat:\n",
        "#             zloc = np.percentile(tt, 10, 0)[2]\n",
        "            zloc = -close_depth * .1\n",
        "            c2w_path[:3,3] = c2w_path[:3,3] + zloc * c2w_path[:3,2]\n",
        "            rads[2] = 0.\n",
        "            N_rots = 1\n",
        "            N_views/=2\n",
        "\n",
        "        # Generate poses for spiral path\n",
        "        render_poses = render_path_spiral(c2w_path, up, rads, focal, zdelta, zrate=.5, rots=N_rots, N=N_views)\n",
        "\n",
        "\n",
        "    render_poses = np.array(render_poses).astype(np.float32)\n",
        "\n",
        "    c2w = poses_avg(poses)\n",
        "    print('Data:')\n",
        "    print(poses.shape, images.shape, bds.shape)\n",
        "\n",
        "    dists = np.sum(np.square(c2w[:3,3] - poses[:,:3,3]), -1)\n",
        "    i_test = np.argmin(dists)\n",
        "    print('HOLDOUT view is', i_test)\n",
        "\n",
        "    images = images.astype(np.float32)\n",
        "    poses = poses.astype(np.float32)\n",
        "\n",
        "    return images, poses, bds, render_poses, i_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt8nSA2XL30E",
        "outputId": "d48537bf-fee6-49c0-a4d9-a2b085119f37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/13/twz8kwfs1qv_4w_c6dzc_57m0000gn/T/ipykernel_14195/2513825885.py:70: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  sh = imageio.imread(img0).shape\n",
            "/var/folders/13/twz8kwfs1qv_4w_c6dzc_57m0000gn/T/ipykernel_14195/2513825885.py:101: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  sh = imageio.imread(imgfiles[0]).shape\n",
            "/var/folders/13/twz8kwfs1qv_4w_c6dzc_57m0000gn/T/ipykernel_14195/2513825885.py:112: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  return imageio.imread(f)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded image data (400, 400, 3, 300) [400.         400.         611.33579277]\n",
            "Loaded /Users/Admin/Desktop/NeRF/Dataset1_Idol 5.036116148152757 9.225723045334737\n",
            "recentered (3, 5)\n",
            "[[ 1.0000000e+00 -5.6752238e-09  3.7130267e-08  1.0331472e-08]\n",
            " [ 5.6752238e-09  1.0000000e+00 -1.4933124e-09  3.7252904e-10]\n",
            " [-3.7130267e-08  1.4933126e-09  1.0000000e+00 -3.0597050e-08]]\n",
            "Data:\n",
            "(300, 3, 5) (300, 400, 400, 3) (300, 2)\n",
            "HOLDOUT view is 149\n"
          ]
        }
      ],
      "source": [
        "images, poses, bds, render_poses, i_test = load_llff_data(basedir, factor=None, recenter=True, bd_factor=.75, spherify=False, path_zflat=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The array of poses is now stored as a numpy compressed file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZRZ1kqCL30I",
        "outputId": "202e14d1-0ac0-4329-d7f9-f12b7eac3fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Array Shape: (300, 3, 5)\n",
            "Modified Array Shape: (300, 4, 4)\n"
          ]
        }
      ],
      "source": [
        "original_array = poses  # Replace this with your actual array\n",
        "\n",
        "# Remove the last column\n",
        "modified_array = np.delete(original_array, -1, axis=2)\n",
        "\n",
        "# Add a new row [0, 0, 0, 1]\n",
        "new_row = np.array([[0, 0, 0, 1]]).astype(np.float32)\n",
        "modified_array = np.concatenate((modified_array, np.tile(new_row, (300, 1, 1))), axis=1)\n",
        "\n",
        "# Display the shapes of the original and modified arrays\n",
        "print(\"Original Array Shape:\", original_array.shape)\n",
        "print(\"Modified Array Shape:\", modified_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6TqmX1kL30M"
      },
      "outputs": [],
      "source": [
        "file_path = \"tiny_nerf_data_60.npz\"\n",
        "np.savez(file_path, images=images[::5,:,:,:], poses=modified_array[::5,:,:], focal=focal)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.18 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
